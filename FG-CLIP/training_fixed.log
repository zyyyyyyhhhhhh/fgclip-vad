========================================
🚀 FG-CLIP UCF 正式训练启动
========================================
📊 数据统计:
  - 训练视频: 232个
  - 数据文件: ucf_fgclip_train_final.json
  - 数据大小: 1.6M

🎯 训练配置:
  - 帧数: 256
  - 批次大小: 2
  - 梯度累积: 8
  - 有效批次: 16
  - 训练轮数: 10

� 模型配置:
  - CLIP模型: ViT-B/32 (本地加载)
  - 本地路径: ./fgclip/model/clip
  - 网络需求: ❌ 无需联网

�💾 输出目录: ./checkpoints/fgclip_ucf_full
🖥️  GPU设备: 0
========================================

⏰ 训练开始时间: 2025-10-12 22:42:22
/data/zyy/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.
============================================================
Loading CLIP components (LOCAL MODE - No Internet Required)
============================================================
Loading tokenizer for: ViT-B/32
  ✓ Tokenizer loaded (local CLIP)
Loading image processor for: ViT-B/32
  ✓ Image processor loaded (local CLIP)
Initializing FG-CLIP model: ViT-B/32
  ✓ Model initialized (random weights)
============================================================
Loading data from: /data/zyy/dataset/UCF_Crimes_Videos/ucf_fgclip_train_final.json
  → Detected list format (new)
Total videos loaded: 232
  - Normal videos: 0
  - Abnormal videos: 232
  0%|          | 0/140 [00:00<?, ?it/s]/data/zyy/wsvad/2026CVPR/FG-CLIP/fgclip/train/train_fgclip.py:562: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  text = torch.tensor(
/data/zyy/wsvad/2026CVPR/FG-CLIP/fgclip/train/train_fgclip.py:567: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  short_text = torch.tensor(
/data/zyy/wsvad/2026CVPR/FG-CLIP/fgclip/train/train_fgclip.py:650: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  box_text = torch.tensor(
/data/zyy/wsvad/2026CVPR/FG-CLIP/fgclip/train/train_fgclip.py:562: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  text = torch.tensor(
/data/zyy/wsvad/2026CVPR/FG-CLIP/fgclip/train/train_fgclip.py:567: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  short_text = torch.tensor(
/data/zyy/wsvad/2026CVPR/FG-CLIP/fgclip/train/train_fgclip.py:650: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  box_text = torch.tensor(
/data/zyy/wsvad/2026CVPR/FG-CLIP/fgclip/train/train_fgclip.py:562: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  text = torch.tensor(
/data/zyy/wsvad/2026CVPR/FG-CLIP/fgclip/train/train_fgclip.py:567: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  short_text = torch.tensor(
/data/zyy/wsvad/2026CVPR/FG-CLIP/fgclip/train/train_fgclip.py:650: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  box_text = torch.tensor(
/data/zyy/wsvad/2026CVPR/FG-CLIP/fgclip/train/train_fgclip.py:562: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  text = torch.tensor(
/data/zyy/wsvad/2026CVPR/FG-CLIP/fgclip/train/train_fgclip.py:567: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  short_text = torch.tensor(
/data/zyy/wsvad/2026CVPR/FG-CLIP/fgclip/train/train_fgclip.py:650: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).
  box_text = torch.tensor(
[LOSS] Total: 0.7553 | Global: 0.6826 | Region: 0.7266 | HardNeg: 0.0000
[LOSS] Total: 0.7867 | Global: 0.7173 | Region: 0.6943 | HardNeg: 0.0000
[LOSS] Total: 0.8389 | Global: 0.7695 | Region: 0.6934 | HardNeg: 0.0000
[LOSS] Total: 0.7992 | Global: 0.7295 | Region: 0.6973 | HardNeg: 0.0000
[LOSS] Total: nan | Global: 0.7891 | Region: nan | HardNeg: 0.0000
[LOSS] Total: 0.7471 | Global: 0.6768 | Region: 0.7031 | HardNeg: 0.0000
[LOSS] Total: 0.8256 | Global: 0.7554 | Region: 0.7021 | HardNeg: 0.0000
[LOSS] Total: 0.8321 | Global: 0.7612 | Region: 0.7090 | HardNeg: 0.0000
  1%|          | 1/140 [00:23<53:48, 23.23s/it][LOSS] Total: nan | Global: nan | Region: nan | HardNeg: 0.0000
[LOSS] Total: nan | Global: nan | Region: nan | HardNeg: 0.0000
[LOSS] Total: nan | Global: nan | Region: nan | HardNeg: 0.0000
[LOSS] Total: nan | Global: nan | Region: nan | HardNeg: 0.0000
[LOSS] Total: nan | Global: nan | Region: nan | HardNeg: 0.0000
[LOSS] Total: nan | Global: nan | Region: nan | HardNeg: 0.0000
[LOSS] Total: nan | Global: nan | Region: nan | HardNeg: 0.0000
[LOSS] Total: nan | Global: nan | Region: nan | HardNeg: 0.0000
  1%|▏         | 2/140 [00:58<1:10:18, 30.57s/it]