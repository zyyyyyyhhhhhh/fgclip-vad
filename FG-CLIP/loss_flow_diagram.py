"""
FG-CLIP 损失计算流程可视化脚本
运行: python loss_flow_diagram.py
"""

def print_loss_flow():
    print("""
╔═══════════════════════════════════════════════════════════════════════════════╗
║                         FG-CLIP 损失计算流程图                                  ║
║                    (Video Anomaly Detection 任务)                             ║
╚═══════════════════════════════════════════════════════════════════════════════╝

┌─────────────────────────────────────────────────────────────────────────────┐
│                              输入数据 (Batch)                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│  • Video Frames:        (B, T, 3, 224, 224)                                │
│  • Video Mask:          (B, T)              [标记有效帧]                      │
│  • Long Text:           (B, 77)             [完整描述]                        │
│  • Short Text:          (B, 77)             [简短描述]                        │
│  • Bbox Coords:         (B, max_anns, 4)   [异常区域坐标]                    │
│  • Bbox Texts:          (B*max_anns, 77)   [区域描述]                        │
│  • Hard Neg Texts:      (B*11, 77)         [1正 + 10负描述]                  │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                          特征提取 (Feature Extraction)                        │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                               │
│  ┌────────────────────┐              ┌─────────────────────┐                │
│  │  Vision Encoder    │              │   Text Encoder      │                │
│  │  (逐帧编码)         │              │   (CLIP Transformer) │                │
│  └────────────────────┘              └─────────────────────┘                │
│           │                                     │                            │
│           ▼                                     ▼                            │
│  Frame Features                        Text Embeddings                      │
│  (B*T, 512)                            • Long:  (B, 512)                    │
│           │                            • Short: (B, 512)                    │
│           ▼                                     │                            │
│  ┌────────────────────┐                        │                            │
│  │ Temporal Modeling  │                        │                            │
│  │ • Transformer      │                        │                            │
│  │ • Attention Pool   │                        │                            │
│  └────────────────────┘                        │                            │
│           │                                     │                            │
│           ▼                                     ▼                            │
│  Video Embeddings                      Normalized Embeddings                │
│  (B, 512)                              (L2 normalized)                      │
│                                                                               │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
╔═════════════════════════════════════════════════════════════════════════════╗
║                         损失计算 (Loss Computation)                          ║
╚═════════════════════════════════════════════════════════════════════════════╝

┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃  ① 全局对比学习损失 (Global Contrastive Loss)                              ┃
┃     权重: 1.0  |  函数: clip_loss()  |  代码: Line 441-446, 603-648      ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛

    收集所有 GPU 特征 (分布式训练)
    ┌─────────────────────────────────────────┐
    │ all_gather(image_embeds)  -> (N, 512)  │  N = 全局 batch size
    │ all_gather(long_text_embeds) -> (N,512)│
    │ all_gather(short_text_embeds)-> (N,512)│
    └─────────────────────────────────────────┘
                    │
                    ▼
    计算相似度矩阵 (Similarity Matrix)
    ┌─────────────────────────────────────────┐
    │ sim_i2t = image @ text.T * exp(τ)      │  τ = logit_scale (可学习)
    │ sim_t2i = text @ image.T * exp(τ)      │
    │                                         │
    │ Shape: (B, N)  [B个样本 vs N个候选]     │
    └─────────────────────────────────────────┘
                    │
                    ▼
    InfoNCE Loss (对角线为正样本)
    ┌─────────────────────────────────────────┐
    │ targets = [rank*B, ..., rank*B + B-1]  │  对角线索引
    │                                         │
    │ loss_long = (CE(sim_i2t, targets) +    │
    │              CE(sim_t2i, targets)) / 2 │
    │                                         │
    │ loss_short = (CE(sim_i2ts, targets) +  │
    │               CE(sim_ts2i, targets))/2 │
    └─────────────────────────────────────────┘
                    │
                    ▼
         loss_global = loss_long + loss_short


┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃  ② 细粒度 Bbox 对比损失 (Fine-grained Box Loss)                            ┃
┃     权重: 0.1  |  函数: pairwise_contrastive_loss()  |  代码: Line 568-581┃
┃     条件: add_box_loss=True  (仅异常视频)                                  ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛

    提取 Region 特征 (RoI Align)
    ┌─────────────────────────────────────────────────────┐
    │ Feature Map: (B*T, 512, h, w)  [每帧的特征图]       │
    │ Bbox Coords: (B, max_anns, 4) [异常区域坐标]        │
    │                                                      │
    │ 1. 扩展 bbox 到所有帧:                               │
    │    (B, max_anns, 4) -> (B*T, max_anns, 4)          │
    │                                                      │
    │ 2. RoI Align 提取每帧每个 bbox 的特征:               │
    │    x_rois = roi_align(feature_map, bbox, (1,1))    │
    │    Shape: (B*T, max_anns, 512)                     │
    │                                                      │
    │ 3. 时序聚合 (Attention Mask 加权平均):               │
    │    x_rois = x_rois.view(B, T, max_anns, 512)       │
    │    mask_weight = video_attention_mask              │
    │    bbox_features = weighted_mean(x_rois, mask)     │
    │    Shape: (B, max_anns, 512)                       │
    │                                                      │
    │ 4. 展平: (B*max_anns, 512)                          │
    └─────────────────────────────────────────────────────┘
                    │
                    ▼
    编码 Bbox 描述文本
    ┌─────────────────────────────────────────┐
    │ bbox_text_embeds = text_encoder(        │
    │     box_texts  # (B*max_anns, 77)       │
    │ )                                       │
    │ Shape: (B*max_anns, 512)                │
    └─────────────────────────────────────────┘
                    │
                    ▼
    过滤有效 Bbox (使用 box_nums)
    ┌─────────────────────────────────────────┐
    │ valid_mask = create_mask(box_nums)      │
    │ bbox_image_embeds = filter(valid_mask)  │
    │ bbox_text_embeds = filter(valid_mask)   │
    └─────────────────────────────────────────┘
                    │
                    ▼
    Pairwise Contrastive Loss
    ┌─────────────────────────────────────────┐
    │ labels = eye(N)  # N = 有效 bbox 总数   │
    │                                         │
    │ logits_i2t = bbox_img @ bbox_text.T    │
    │ logits_t2i = bbox_text @ bbox_img.T    │
    │                                         │
    │ loss_bbox = (CE(logits_i2t, labels) +  │
    │              CE(logits_t2i, labels))/2 │
    └─────────────────────────────────────────┘
                    │
                    ▼
         loss_bbox = 0.1 * loss_bbox


┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃  ③ 困难负样本对比损失 (Hard Negative Loss)                                 ┃
┃     权重: 0.5  |  函数: hard_contrastive_loss()  |  代码: Line 584-596    ┃
┃     条件: use_hard_neg=True  (可选)                                       ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛

    提取困难负样本区域特征
    ┌─────────────────────────────────────────┐
    │ hard_bbox_features = roi_align(...)     │
    │ Shape: (B*hard_nums, 512)               │
    └─────────────────────────────────────────┘
                    │
                    ▼
    编码困难负样本文本 (1正 + 10负)
    ┌─────────────────────────────────────────┐
    │ hard_text_embeds = text_encoder(        │
    │     hard_texts  # (B*11, 77)            │
    │ )                                       │
    │ Shape: (B*11, 512) -> (B, 11, 512)      │
    └─────────────────────────────────────────┘
                    │
                    ▼
    计算相似度 (选择最相似的描述)
    ┌─────────────────────────────────────────┐
    │ similarity = einsum('bp,bdp->bd',       │
    │     hard_bbox_img,    # (B, 512)        │
    │     hard_text         # (B, 11, 512)    │
    │ )                                       │
    │ Shape: (B, 11)  [每个样本对11个描述打分] │
    └─────────────────────────────────────────┘
                    │
                    ▼
    分类损失 (鼓励选择 index=0 的正确描述)
    ┌─────────────────────────────────────────┐
    │ labels = [0, 0, ..., 0]  # 长度 B       │
    │ loss_hard = CE(similarity, labels)      │
    └─────────────────────────────────────────┘
                    │
                    ▼
         loss_hard = 0.5 * loss_hard


╔═════════════════════════════════════════════════════════════════════════════╗
║                              总损失汇总                                       ║
╚═════════════════════════════════════════════════════════════════════════════╝

    ┌──────────────────────────────────────────────────────────────┐
    │                                                               │
    │  Total Loss = loss_global                                    │
    │               + 0.1 * loss_bbox      (if add_box_loss)       │
    │               + 0.5 * loss_hard      (if use_hard_neg)       │
    │                                                               │
    │  其中:                                                         │
    │    loss_global = loss_long + loss_short                      │
    │                                                               │
    └──────────────────────────────────────────────────────────────┘


╔═════════════════════════════════════════════════════════════════════════════╗
║                         关键参数与可学习温度                                  ║
╚═════════════════════════════════════════════════════════════════════════════╝

    • logit_scale (全局对比):          可学习标量, 初始值 ≈ ln(1/0.07)
    • logit_scale_finegraind (bbox):   可学习标量, 用于细粒度对比
    • logit_scale_hardneg (困难负样本):  可学习标量, 用于困难样本区分


╔═════════════════════════════════════════════════════════════════════════════╗
║                           训练目标与作用                                      ║
╚═════════════════════════════════════════════════════════════════════════════╝

    ① 全局对比学习:
       • 学习视频级别的语义对齐
       • 正样本: 视频与其描述配对
       • 负样本: batch 内其他视频-文本组合
       • 扩大负样本数量: 使用分布式 all_gather

    ② 细粒度 Bbox 对比:
       • 学习局部区域与描述的对齐
       • 正样本: bbox region 与其描述配对
       • 负样本: 其他 region-描述组合
       • 适用场景: 异常视频有标注的异常区域

    ③ 困难负样本对比:
       • 增强区分相似但错误描述的能力
       • 正样本: 第 0 个文本 (正确描述)
       • 负样本: 第 1-10 个文本 (混淆描述)
       • 提升模型鲁棒性


╔═════════════════════════════════════════════════════════════════════════════╗
║                         VAD 任务的关键修改                                    ║
╚═════════════════════════════════════════════════════════════════════════════╝

    ✓ 视频输入处理:
      - 逐帧编码: (B, T, 3, H, W) -> (B*T, 512)
      - 时序建模: Transformer + Attention Pooling
      - 输出: (B, 512) 视频级特征

    ✓ Attention Mask 支持:
      - 标记有效帧: video_attention_mask (B, T)
      - 时序聚合时加权平均
      - 忽略填充帧的贡献

    ✓ 动态 RoI Align:
      - Bbox 扩展到所有帧
      - 每帧独立提取 region 特征
      - 时序聚合得到视频级 region 特征

    ✓ Feature Map 提取:
      - 支持 5D 视频输入检测
      - 自动处理 (B*T, D, h, w) 格式


═══════════════════════════════════════════════════════════════════════════════
生成时间: 2025-10-09
作者: GitHub Copilot
项目: FG-CLIP for Video Anomaly Detection
═══════════════════════════════════════════════════════════════════════════════
""")

if __name__ == "__main__":
    print_loss_flow()
