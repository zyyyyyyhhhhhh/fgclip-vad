#!/bin/bash

# ============================================
# FG-CLIP UCF æ­£å¼è®­ç»ƒé…ç½®
# ä½¿ç”¨å®Œæ•´çš„ 232 ä¸ªè§†é¢‘è¿›è¡Œæ¨¡å‹è®­ç»ƒ
# ============================================

# ç¯å¢ƒé…ç½®
export CUDA_VISIBLE_DEVICES=0
export PYTHONPATH="${PYTHONPATH}:$(pwd)"  # å°†å½“å‰ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„

# ============================================
# æ ¸å¿ƒé…ç½® - æ­£å¼è®­ç»ƒ
# ============================================

# æ•°æ®é…ç½®
DATA_PATH="/data/zyy/dataset/UCF_Crimes_Videos/ucf_fgclip_train_with_timestamps_en.json"  # âœ… è‹±æ–‡ç¿»è¯‘ç‰ˆæœ¬ï¼Œ1559ä¸ªæ ·æœ¬
IMAGE_FOLDER="/data/zyy/dataset"
OUTPUT_DIR="./checkpoints/fgclip_ucf_full"

# æ¨¡å‹é…ç½® - ä½¿ç”¨æœ¬åœ°CLIPï¼ˆä¸éœ€è¦è”ç½‘ï¼‰
BASE_MODEL="ViT-B/32"       # æœ¬åœ°CLIPæ¨¡å‹åç§°ï¼Œä¸éœ€è¦å‰ç¼€"openai/"
LOCAL_CLIP_PATH="./fgclip/model/clip"  # æœ¬åœ°CLIPä»£ç è·¯å¾„

# ============================================
# è®­ç»ƒè¶…å‚æ•° - æ ¹æ®Claudeå»ºè®®ä¼˜åŒ–
# ============================================

# è§†é¢‘é…ç½®
NUM_FRAMES=256              # Global: 256 å¸§ï¼ŒRegion: 128 å¸§ï¼ˆä»£ç ä¸­è‡ªåŠ¨å‡åŠï¼‰
BATCH_SIZE=2                # âœ… é™ä½åˆ° 2ï¼ˆ24GB æ˜¾å­˜ä¼˜åŒ–ï¼‰
GRAD_ACCUM=16               # âœ… å¢åŠ æ¢¯åº¦ç´¯ç§¯ï¼ˆæœ‰æ•ˆbatch=2*16=32ï¼‰

# è®­ç»ƒé…ç½®
EPOCHS=5                    # é»˜è®¤è®­ç»ƒ 5 ä¸ª epochï¼Œå¯æŒ‰éœ€è°ƒæ•´
LEARNING_RATE=5e-6          # âœ… é™ä½å­¦ä¹ ç‡é˜²æ­¢NaNï¼ˆ1e-5 â†’ 5e-6ï¼‰
TEXT_LR=2e-6                # æ–‡æœ¬ç¼–ç å™¨æ›´å°å­¦ä¹ ç‡ï¼ˆ5e-6 â†’ 2e-6ï¼‰
WARMUP_RATIO=0.1            # 10%æ­¥æ•°ç”¨äºwarmup
MAX_GRAD_NORM=1.0           # âœ… æ·»åŠ æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸

# ä¿å­˜ç­–ç•¥
SAVE_STEPS=100              # æ¯100æ­¥ä¿å­˜ä¸€æ¬¡ (ä¸åƒè°ƒè¯•çš„5æ­¥)
SAVE_TOTAL_LIMIT=3          # ä¿ç•™æœ€è¿‘3ä¸ªcheckpoint
LOGGING_STEPS=10            # æ¯10æ­¥è®°å½•ä¸€æ¬¡

# æ•ˆç‡ä¼˜åŒ–
NUM_WORKERS=2               # âœ… é™ä½åˆ°2,å‡å°‘å†…å­˜å‹åŠ›(åŸæ¥4ä¸ªworkerå¤ªå¤š)
GRAD_CHECKPOINT=True        # æ¢¯åº¦æ£€æŸ¥ç‚¹èŠ‚çœæ˜¾å­˜
AUTO_RESUME=False            # âœ… è‹¥éœ€ä»å¤´å¼€å§‹è®­ç»ƒï¼Œå°†å…¶è®¾ä¸º False

echo "========================================"
echo "ğŸš€ FG-CLIP UCF æ­£å¼è®­ç»ƒå¯åŠ¨"
echo "========================================"
echo "ğŸ“Š æ•°æ®ç»Ÿè®¡:"
echo "  - è®­ç»ƒæ ·æœ¬: çº¦1812ä¸ªregionsï¼ˆ253å¼‚å¸¸è§†é¢‘ + 1306æ­£å¸¸ç‰‡æ®µï¼‰"
echo "  - æ•°æ®æ–‡ä»¶: $(basename ${DATA_PATH})"
echo "  - æ•°æ®å¤§å°: $(ls -lh ${DATA_PATH} 2>/dev/null | awk '{print $5}' || echo 'N/A')"
echo ""
echo "ğŸ¯ è®­ç»ƒé…ç½®:"
echo "  - å¸§æ•°: ${NUM_FRAMES}"
echo "  - æ‰¹æ¬¡å¤§å°: ${BATCH_SIZE}"
echo "  - æ¢¯åº¦ç´¯ç§¯: ${GRAD_ACCUM}"
echo "  - æœ‰æ•ˆæ‰¹æ¬¡: $((BATCH_SIZE * GRAD_ACCUM))"
echo "  - è®­ç»ƒè½®æ•°: ${EPOCHS}"
echo "  - âœ… æ¯ä¸ªregionç‹¬ç«‹å¯¹æ¯”å­¦ä¹ "
echo ""
echo "ï¿½ æ¨¡å‹é…ç½®:"
echo "  - CLIPæ¨¡å‹: ${BASE_MODEL} (æœ¬åœ°åŠ è½½)"
echo "  - æœ¬åœ°è·¯å¾„: ${LOCAL_CLIP_PATH}"
echo "  - ç½‘ç»œéœ€æ±‚: âŒ æ— éœ€è”ç½‘"
echo ""
echo "ï¿½ğŸ’¾ è¾“å‡ºç›®å½•: ${OUTPUT_DIR}"
echo "ğŸ–¥ï¸  GPUè®¾å¤‡: ${CUDA_VISIBLE_DEVICES}"
echo "========================================"
echo ""

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
if [ ! -f "${DATA_PATH}" ]; then
    echo "âŒ é”™è¯¯: æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: ${DATA_PATH}"
    exit 1
fi

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p ${OUTPUT_DIR}

# è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
START_TIME=$(date '+%Y-%m-%d %H:%M:%S')
echo "â° è®­ç»ƒå¼€å§‹æ—¶é—´: ${START_TIME}" | tee ${OUTPUT_DIR}/training_start.log

# ============================================
# å¯åŠ¨è®­ç»ƒ
# ============================================

python3 fgclip/train/train_fgclip.py \
    --model_name_or_path ${BASE_MODEL} \
    --base_model ${BASE_MODEL} \
    --data_path ${DATA_PATH} \
    --image_folder ${IMAGE_FOLDER} \
    --output_dir ${OUTPUT_DIR} \
    \
    --is_video True \
    --num_frames ${NUM_FRAMES} \
    --is_multimodal True \
    --add_box_loss True \
    --from_openai True \
    \
    --bf16 True \
    --num_train_epochs ${EPOCHS} \
    --per_device_train_batch_size ${BATCH_SIZE} \
    --gradient_accumulation_steps ${GRAD_ACCUM} \
    --evaluation_strategy "no" \
    --save_strategy "steps" \
    --save_steps ${SAVE_STEPS} \
    --save_total_limit ${SAVE_TOTAL_LIMIT} \
    --learning_rate ${LEARNING_RATE} \
    --text_model_lr ${TEXT_LR} \
    --max_grad_norm ${MAX_GRAD_NORM} \
    --weight_decay 0.01 \
    --warmup_ratio ${WARMUP_RATIO} \
    --lr_scheduler_type "cosine" \
    --logging_steps ${LOGGING_STEPS} \
    --tf32 True \
    --gradient_checkpointing ${GRAD_CHECKPOINT} \
    --dataloader_num_workers ${NUM_WORKERS} \
    --auto_resume ${AUTO_RESUME} \
    --report_to tensorboard \
    --seed 42

# è®°å½•è®­ç»ƒç»“æŸæ—¶é—´
TRAIN_EXIT_CODE=$?
END_TIME=$(date '+%Y-%m-%d %H:%M:%S')

echo ""
echo "========================================"
if [ ${TRAIN_EXIT_CODE} -eq 0 ]; then
    echo "âœ… è®­ç»ƒæˆåŠŸå®Œæˆï¼"
else
    echo "âŒ è®­ç»ƒå¼‚å¸¸é€€å‡º (Exit Code: ${TRAIN_EXIT_CODE})"
fi
echo "========================================"
echo "â° å¼€å§‹æ—¶é—´: ${START_TIME}"
echo "â° ç»“æŸæ—¶é—´: ${END_TIME}"
echo ""
echo "ğŸ“‚ è¾“å‡ºç›®å½•: ${OUTPUT_DIR}"
echo "ğŸ“Š TensorBoard: tensorboard --logdir ${OUTPUT_DIR} --port 6006"
echo "ğŸ“ è®­ç»ƒæ—¥å¿—: tail -f ${OUTPUT_DIR}/trainer_log.txt"
echo "========================================"

exit ${TRAIN_EXIT_CODE}
