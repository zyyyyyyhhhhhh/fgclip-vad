#!/usr/bin/env python3
"""
è®­ç»ƒå‰å®Œæ•´éªŒè¯è„šæœ¬
æ£€æŸ¥æ‰€æœ‰P0é—®é¢˜æ˜¯å¦å·²ä¿®å¤
"""

import os
import sys
import json
import torch
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

print("=" * 80)
print("ğŸ” FG-CLIP VAD è®­ç»ƒå‰éªŒè¯")
print("=" * 80)

# ============ æµ‹è¯•1: æœ¬åœ°CLIPåŠ è½½ ============
print("\n" + "=" * 80)
print("æµ‹è¯• 1: æœ¬åœ°CLIPç»„ä»¶åŠ è½½ï¼ˆæ— éœ€ç½‘ç»œï¼‰")
print("=" * 80)

try:
    from fgclip.train.local_clip_loader import LocalCLIPWrapper
    
    # æµ‹è¯•tokenizer
    print("\n1.1 æµ‹è¯• Tokenizer...")
    tokenizer = LocalCLIPWrapper.get_tokenizer()
    test_texts = [
        "A man in a white shirt and black pants",
        "A woman running on the street"
    ]
    tokens = tokenizer(test_texts, max_length=77, truncation=True)
    print(f"   âœ“ Tokenizer å·¥ä½œæ­£å¸¸")
    print(f"   - è¾“å…¥æ–‡æœ¬æ•°: {len(test_texts)}")
    print(f"   - Token shape: {tokens['input_ids'].shape}")
    print(f"   - ç¤ºä¾‹æ–‡æœ¬: '{test_texts[0][:50]}...'")
    
    # æµ‹è¯•image processor
    print("\n1.2 æµ‹è¯• Image Processor...")
    processor = LocalCLIPWrapper.get_image_processor()
    from PIL import Image
    import numpy as np
    dummy_image = Image.fromarray(np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8))
    processed = processor.preprocess(dummy_image)
    print(f"   âœ“ Image Processor å·¥ä½œæ­£å¸¸")
    print(f"   - è¾“å…¥å›¾åƒ: {dummy_image.size}")
    print(f"   - å¤„ç†åshape: {processed['pixel_values'].shape}")
    print(f"   - å€¼åŸŸ: [{processed['pixel_values'].min():.3f}, {processed['pixel_values'].max():.3f}]")
    
    print("\nâœ… æœ¬åœ°CLIPåŠ è½½æµ‹è¯•é€šè¿‡ï¼")
    
except Exception as e:
    print(f"\nâŒ æœ¬åœ°CLIPåŠ è½½å¤±è´¥: {e}")
    print("   è¯·æ£€æŸ¥ fgclip/model/clip/ ç›®å½•æ˜¯å¦å®Œæ•´")
    sys.exit(1)


# ============ æµ‹è¯•2: æ•°æ®æ ¼å¼å…¼å®¹æ€§ ============
print("\n" + "=" * 80)
print("æµ‹è¯• 2: æ•°æ®æ ¼å¼å…¼å®¹æ€§")
print("=" * 80)

data_path = "/data/zyy/dataset/UCF_Crimes_Videos/ucf_fgclip_train_final.json"
print(f"\næ•°æ®æ–‡ä»¶: {data_path}")

if not os.path.exists(data_path):
    print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
    sys.exit(1)

try:
    with open(data_path, 'r') as f:
        data = json.load(f)
    
    print(f"   âœ“ JSONåŠ è½½æˆåŠŸ")
    print(f"   - æ•°æ®ç±»å‹: {type(data).__name__}")
    print(f"   - è§†é¢‘æ•°é‡: {len(data)}")
    
    # æ£€æŸ¥æ ¼å¼
    if isinstance(data, list):
        print(f"   âœ“ æ£€æµ‹åˆ°åˆ—è¡¨æ ¼å¼ï¼ˆæ–°æ ¼å¼ï¼‰")
        sample = data[0]
        print(f"   - æ ·æœ¬å­—æ®µ: {list(sample.keys())}")
        
        # éªŒè¯å¿…è¦å­—æ®µ
        required_fields = ['f_path', 'global_caption', 'bbox_info']
        missing = [f for f in required_fields if f not in sample]
        if missing:
            print(f"   âŒ ç¼ºå°‘å¿…è¦å­—æ®µ: {missing}")
            sys.exit(1)
        else:
            print(f"   âœ“ æ‰€æœ‰å¿…è¦å­—æ®µéƒ½å­˜åœ¨")
        
        # æ£€æŸ¥bbox_infoç»“æ„
        bbox_info = sample['bbox_info']
        print(f"   - Regionæ•°é‡: {len(bbox_info)}")
        if len(bbox_info) > 0:
            region_keys = list(bbox_info[0].keys())
            print(f"   - Regionå­—æ®µ: {region_keys}")
            
            has_keyframes = 'keyframes' in region_keys
            print(f"   - æ˜¯å¦æœ‰keyframes: {has_keyframes}")
            
    elif isinstance(data, dict):
        print(f"   âœ“ æ£€æµ‹åˆ°å­—å…¸æ ¼å¼ï¼ˆæ—§æ ¼å¼ï¼‰")
        print(f"   - è§†é¢‘åç§°ï¼ˆå‰3ä¸ªï¼‰: {list(data.keys())[:3]}")
    
    print("\nâœ… æ•°æ®æ ¼å¼æµ‹è¯•é€šè¿‡ï¼")
    
except Exception as e:
    print(f"\nâŒ æ•°æ®æ ¼å¼æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)


# ============ æµ‹è¯•3: è§†é¢‘è·¯å¾„éªŒè¯ ============
print("\n" + "=" * 80)
print("æµ‹è¯• 3: è§†é¢‘æ–‡ä»¶è·¯å¾„éªŒè¯")
print("=" * 80)

image_folder = "/data/zyy/dataset"
print(f"\nåŸºç¡€è·¯å¾„: {image_folder}")

# ä»æ•°æ®ä¸­æå–è§†é¢‘ä¿¡æ¯
sample = data[0]
f_path = sample['f_path']
video_name = os.path.basename(f_path)
print(f"æ ·æœ¬è§†é¢‘: {video_name}")

# æå–ç±»åˆ«
import re
match = re.match(r"([A-Za-z]+)", video_name)
if match:
    category = match.group(1)
    print(f"æå–çš„ç±»åˆ«: {category}")
else:
    print(f"âŒ æ— æ³•ä»æ–‡ä»¶åæå–ç±»åˆ«: {video_name}")
    sys.exit(1)

# æ„å»ºå®Œæ•´è·¯å¾„ï¼ˆä½¿ç”¨ä¿®å¤åçš„é€»è¾‘ï¼‰
video_full_path = os.path.join(
    image_folder,
    "UCF_Crimes_Videos",
    "UCF_Crimes",
    "Videos",
    category,
    video_name
)

print(f"\næ„å»ºçš„å®Œæ•´è·¯å¾„:")
print(f"  {video_full_path}")

# æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
if os.path.exists(video_full_path):
    print(f"   âœ“ è§†é¢‘æ–‡ä»¶å­˜åœ¨")
    file_size = os.path.getsize(video_full_path) / (1024 * 1024)
    print(f"   - æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
else:
    print(f"   âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨!")
    
    # å°è¯•åˆ—å‡ºå¯èƒ½çš„è·¯å¾„
    print(f"\nè°ƒè¯•ä¿¡æ¯ - æ£€æŸ¥ç›®å½•ç»“æ„:")
    
    check_paths = [
        os.path.join(image_folder, "UCF_Crimes_Videos"),
        os.path.join(image_folder, "UCF_Crimes_Videos", "UCF_Crimes"),
        os.path.join(image_folder, "UCF_Crimes_Videos", "UCF_Crimes", "Videos"),
        os.path.join(image_folder, "UCF_Crimes_Videos", "UCF_Crimes", "Videos", category),
    ]
    
    for path in check_paths:
        exists = os.path.exists(path)
        status = "âœ“" if exists else "âœ—"
        print(f"   {status} {path}")
        if exists and os.path.isdir(path):
            contents = os.listdir(path)[:5]
            print(f"      å†…å®¹ï¼ˆå‰5é¡¹ï¼‰: {contents}")
    
    sys.exit(1)

# æ£€æŸ¥æ›´å¤šè§†é¢‘ï¼ˆå‰10ä¸ªï¼‰
print(f"\néªŒè¯æ›´å¤šè§†é¢‘ï¼ˆå‰10ä¸ªï¼‰:")
check_count = min(10, len(data))
exists_count = 0

for i in range(check_count):
    item = data[i]
    video_name = os.path.basename(item['f_path'])
    match = re.match(r"([A-Za-z]+)", video_name)
    if not match:
        continue
    category = match.group(1)
    
    video_path = os.path.join(
        image_folder,
        "UCF_Crimes_Videos",
        "UCF_Crimes",
        "Videos",
        category,
        video_name
    )
    
    exists = os.path.exists(video_path)
    status = "âœ“" if exists else "âœ—"
    print(f"   {status} [{i+1:2d}] {category:15s} {video_name}")
    
    if exists:
        exists_count += 1

success_rate = (exists_count / check_count) * 100
print(f"\næˆåŠŸç‡: {exists_count}/{check_count} ({success_rate:.1f}%)")

if exists_count == check_count:
    print("âœ… è§†é¢‘è·¯å¾„éªŒè¯é€šè¿‡ï¼")
else:
    print(f"âš ï¸  æœ‰ {check_count - exists_count} ä¸ªè§†é¢‘æ–‡ä»¶ç¼ºå¤±")
    if success_rate < 50:
        print("âŒ æˆåŠŸç‡è¿‡ä½ï¼Œè¯·æ£€æŸ¥è§†é¢‘ç›®å½•ç»“æ„")
        sys.exit(1)


# ============ æµ‹è¯•4: æ•°æ®åŠ è½½å®Œæ•´æµç¨‹ ============
print("\n" + "=" * 80)
print("æµ‹è¯• 4: æ•°æ®åŠ è½½å®Œæ•´æµç¨‹")
print("=" * 80)

try:
    print("\nåˆå§‹åŒ–æ•°æ®é›†...")
    
    # åˆ›å»ºå¿…è¦çš„é…ç½®
    from dataclasses import dataclass, field
    from typing import Optional
    
    @dataclass
    class TestDataArguments:
        data_path: str = data_path
        image_folder: str = image_folder
        lazy_preprocess: bool = False
        is_multimodal: bool = True
        max_seq_length: int = 77*4-60
        base_seq_length: int = 77
        base_image_size: int = 224
        add_box_loss: bool = True
        use_hard_neg: bool = False
        is_video: bool = True
        num_frames: int = 64  # è°ƒè¯•ç”¨
    
    data_args = TestDataArguments()
    
    # å¯¼å…¥æ•°æ®é›†ç±»
    from fgclip.train.train_fgclip import LazySupervisedBboxDataset
    
    print("   åˆ›å»ºæ•°æ®é›†å¯¹è±¡...")
    dataset = LazySupervisedBboxDataset(
        data_path=data_args.data_path,
        data_args=data_args,
        img_preprocess=processor,
        tokenizer=tokenizer
    )
    
    print(f"   âœ“ æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
    print(f"   - æ€»è§†é¢‘æ•°: {len(dataset)}")
    
    # æµ‹è¯•åŠ è½½ç¬¬ä¸€ä¸ªæ ·æœ¬
    print("\n   åŠ è½½ç¬¬ä¸€ä¸ªæ ·æœ¬...")
    sample = dataset[0]
    
    print(f"   âœ“ æ ·æœ¬åŠ è½½æˆåŠŸ")
    print(f"   - video shape: {sample['video'].shape}")
    print(f"   - text shape: {sample['text'].shape}")
    print(f"   - box_infos shape: {sample['box_infos'].shape}")
    print(f"   - bbox_mask shape: {sample['bbox_mask'].shape}")
    print(f"   - video_attention_mask shape: {sample['video_attention_mask'].shape}")
    
    # éªŒè¯æ•°æ®èŒƒå›´
    video_min, video_max = sample['video'].min(), sample['video'].max()
    print(f"   - videoå€¼åŸŸ: [{video_min:.3f}, {video_max:.3f}]")
    
    # æ£€æŸ¥bboxæœ‰æ•ˆæ€§
    valid_bboxes = sample['bbox_mask'].sum().item()
    total_bboxes = sample['bbox_mask'].numel()
    print(f"   - æœ‰æ•ˆbbox: {valid_bboxes}/{total_bboxes}")
    
    print("\nâœ… æ•°æ®åŠ è½½æµ‹è¯•é€šè¿‡ï¼")
    
except Exception as e:
    print(f"\nâŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)


# ============ æœ€ç»ˆæ€»ç»“ ============
print("\n" + "=" * 80)
print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è®­ç»ƒå‡†å¤‡å°±ç»ªï¼")
print("=" * 80)

print("\nä¸‹ä¸€æ­¥:")
print("  1. è¿è¡Œè°ƒè¯•è®­ç»ƒ:")
print("     bash scripts/train_ucf_debug.sh")
print("")
print("  2. ç›‘æ§è®­ç»ƒ:")
print("     tail -f checkpoints/fgclip_ucf_debug/trainer_log.txt")
print("")
print("  3. æŸ¥çœ‹TensorBoard:")
print("     tensorboard --logdir checkpoints/fgclip_ucf_debug")
print("")
print("=" * 80)
