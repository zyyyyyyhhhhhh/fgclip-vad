#!/usr/bin/env python3
"""
è®­ç»ƒå‰ç½®éªŒè¯è„šæœ¬
éªŒè¯æ‰€æœ‰æ•°æ®è·¯å¾„ã€æ ¼å¼å’Œæ¨¡å‹é…ç½®æ˜¯å¦æ­£ç¡®
"""

import os
import sys
import json
import torch
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/data/zyy/wsvad/2026CVPR/FG-CLIP')

def print_section(title):
    """æ‰“å°åˆ†éš”ç¬¦"""
    print("\n" + "="*70)
    print(f"  {title}")
    print("="*70)

def validate_json_format():
    """éªŒè¯JSONæ•°æ®æ ¼å¼"""
    print_section("1ï¸âƒ£  éªŒè¯JSONæ•°æ®æ ¼å¼")
    
    json_path = "/data/zyy/dataset/UCF_Crimes_Videos/ucf_fgclip_train_final.json"
    
    print(f"ğŸ“ JSONè·¯å¾„: {json_path}")
    
    if not os.path.exists(json_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        return False
    
    print(f"âœ… æ–‡ä»¶å­˜åœ¨")
    
    # åŠ è½½æ•°æ®
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… JSONåŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ JSONåŠ è½½å¤±è´¥: {e}")
        return False
    
    # æ£€æŸ¥æ ¼å¼
    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   ç±»å‹: {type(data)}")
    
    if isinstance(data, list):
        print(f"   æ ¼å¼: åˆ—è¡¨æ ¼å¼ (æ–°)")
        print(f"   è§†é¢‘æ•°é‡: {len(data)}")
        
        if len(data) > 0:
            sample = data[0]
            print(f"\nğŸ“ ç¬¬ä¸€ä¸ªè§†é¢‘æ ·æœ¬:")
            print(f"   Keys: {list(sample.keys())}")
            print(f"   f_path: {sample.get('f_path', 'N/A')}")
            print(f"   global_caption é•¿åº¦: {len(sample.get('global_caption', ''))}")
            print(f"   bbox_info æ•°é‡: {len(sample.get('bbox_info', []))}")
            
            # æ£€æŸ¥bbox_infoæ ¼å¼
            if len(sample.get('bbox_info', [])) > 0:
                bbox = sample['bbox_info'][0]
                print(f"   bbox_info[0] keys: {list(bbox.keys())}")
                if 'keyframes' in bbox:
                    print(f"   âœ… æ£€æµ‹åˆ°å¼‚å¸¸è§†é¢‘ï¼ˆæœ‰keyframesï¼‰")
                else:
                    print(f"   â„¹ï¸  æ­£å¸¸è§†é¢‘ï¼ˆæ— keyframesï¼‰")
    
    elif isinstance(data, dict):
        print(f"   æ ¼å¼: å­—å…¸æ ¼å¼ (æ—§)")
        print(f"   è§†é¢‘æ•°é‡: {len(data)}")
    else:
        print(f"âŒ æœªçŸ¥æ ¼å¼: {type(data)}")
        return False
    
    print(f"\nâœ… JSONæ ¼å¼éªŒè¯é€šè¿‡")
    return True


def validate_video_paths():
    """éªŒè¯è§†é¢‘æ–‡ä»¶è·¯å¾„"""
    print_section("2ï¸âƒ£  éªŒè¯è§†é¢‘æ–‡ä»¶è·¯å¾„")
    
    json_path = "/data/zyy/dataset/UCF_Crimes_Videos/ucf_fgclip_train_final.json"
    base_path = "/data/zyy/dataset"
    
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # æµ‹è¯•å‰3ä¸ªè§†é¢‘
    test_count = min(3, len(data) if isinstance(data, list) else 0)
    
    print(f"ğŸ“ åŸºç¡€è·¯å¾„: {base_path}")
    print(f"ğŸ¬ æµ‹è¯•è§†é¢‘æ•°é‡: {test_count}\n")
    
    success_count = 0
    
    for i in range(test_count):
        item = data[i]
        f_path = item.get('f_path', '')
        video_name = os.path.basename(f_path)
        
        # æå–ç±»åˆ«
        import re
        if video_name.startswith("Normal_Videos"):
            category = "Training_Normal_Videos_Anomaly"
        else:
            match = re.match(r"([A-Za-z]+)", video_name)
            category = match.group(1) if match else "Unknown"
        
        # æ„å»ºå®Œæ•´è·¯å¾„
        full_path = os.path.join(
            base_path,
            "UCF_Crimes_Videos",
            "UCF_Crimes",
            "Videos",
            category,
            video_name
        )
        
        print(f"è§†é¢‘ {i+1}:")
        print(f"  åŸå§‹è·¯å¾„: {f_path}")
        print(f"  è§†é¢‘åç§°: {video_name}")
        print(f"  ç±»åˆ«: {category}")
        print(f"  å®Œæ•´è·¯å¾„: {full_path}")
        
        if os.path.exists(full_path):
            file_size = os.path.getsize(full_path) / (1024 * 1024)  # MB
            print(f"  âœ… æ–‡ä»¶å­˜åœ¨ ({file_size:.2f} MB)")
            success_count += 1
        else:
            print(f"  âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        print()
    
    if success_count == test_count:
        print(f"âœ… æ‰€æœ‰æµ‹è¯•è§†é¢‘è·¯å¾„éªŒè¯é€šè¿‡ ({success_count}/{test_count})")
        return True
    else:
        print(f"âš ï¸  éƒ¨åˆ†è§†é¢‘è·¯å¾„æœ‰é—®é¢˜ ({success_count}/{test_count})")
        return False


def validate_model_loading():
    """éªŒè¯æ¨¡å‹åŠ è½½"""
    print_section("3ï¸âƒ£  éªŒè¯æ¨¡å‹å’ŒTokenizeråŠ è½½")
    
    try:
        from transformers import CLIPTokenizer, CLIPImageProcessor
        
        model_name = "openai/clip-vit-base-patch32"
        print(f"ğŸ“¦ æ¨¡å‹: {model_name}\n")
        
        # æµ‹è¯•Tokenizer
        print("æ­£åœ¨åŠ è½½ Tokenizer...")
        tokenizer = CLIPTokenizer.from_pretrained(model_name)
        print("âœ… Tokenizer åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•è‹±æ–‡ç¼–ç 
        test_text_en = "A man punched a woman in the street"
        tokens = tokenizer(test_text_en, return_tensors='pt')
        print(f"   è‹±æ–‡æµ‹è¯•: '{test_text_en}'")
        print(f"   Token shape: {tokens['input_ids'].shape}")
        
        # æµ‹è¯•ImageProcessor
        print("\næ­£åœ¨åŠ è½½ ImageProcessor...")
        processor = CLIPImageProcessor.from_pretrained(model_name)
        print("âœ… ImageProcessor åŠ è½½æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False


def validate_data_loading():
    """éªŒè¯æ•°æ®åŠ è½½æµç¨‹"""
    print_section("4ï¸âƒ£  éªŒè¯æ•°æ®åŠ è½½æµç¨‹")
    
    try:
        from fgclip.train.train_fgclip import LazySupervisedBboxDataset, DataArguments
        from transformers import CLIPTokenizer, CLIPImageProcessor
        from dataclasses import dataclass
        
        print("ğŸ“ åˆ›å»ºæ•°æ®é…ç½®...")
        
        # åˆ›å»ºDataArguments
        data_args = DataArguments(
            data_path="/data/zyy/dataset/UCF_Crimes_Videos/ucf_fgclip_train_final.json",
            image_folder="/data/zyy/dataset",
            is_video=True,
            num_frames=64,  # æµ‹è¯•ç”¨è¾ƒå°‘å¸§æ•°
            add_box_loss=True,
            lazy_preprocess=False,
            is_multimodal=True
        )
        print("âœ… DataArguments åˆ›å»ºæˆåŠŸ")
        
        # åŠ è½½tokenizerå’Œprocessor
        print("\nğŸ“¦ åŠ è½½ Tokenizer å’Œ Processor...")
        tokenizer = CLIPTokenizer.from_pretrained('openai/clip-vit-base-patch32')
        processor = CLIPImageProcessor.from_pretrained('openai/clip-vit-base-patch32')
        print("âœ… åŠ è½½æˆåŠŸ")
        
        # åˆ›å»ºæ•°æ®é›†
        print("\nğŸ“Š åˆ›å»ºæ•°æ®é›†...")
        dataset = LazySupervisedBboxDataset(
            data_path=data_args.data_path,
            data_args=data_args,
            img_preprocess=processor,
            tokenizer=tokenizer
        )
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        print(f"   æ€»è§†é¢‘æ•°: {len(dataset)}")
        
        # æµ‹è¯•åŠ è½½ç¬¬ä¸€ä¸ªæ ·æœ¬
        print("\nğŸ¬ æµ‹è¯•åŠ è½½ç¬¬ä¸€ä¸ªè§†é¢‘...")
        try:
            sample = dataset[0]
            print("âœ… è§†é¢‘åŠ è½½æˆåŠŸï¼")
            print(f"\nğŸ“ æ•°æ®å½¢çŠ¶:")
            print(f"   video: {sample['video'].shape}")
            print(f"   video_attention_mask: {sample['video_attention_mask'].shape}")
            print(f"   text: {sample['text'].shape}")
            print(f"   text_short: {sample['text_short'].shape}")
            
            if 'box_infos' in sample:
                print(f"   box_infos: {sample['box_infos'].shape}")
            if 'bbox_mask' in sample:
                print(f"   bbox_mask: {sample['bbox_mask'].shape}")
            if 'box_nums' in sample:
                print(f"   box_nums: {sample['box_nums']}")
            
            return True
            
        except Exception as e:
            print(f"âŒ è§†é¢‘åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½æµç¨‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def validate_cuda():
    """éªŒè¯CUDAå¯ç”¨æ€§"""
    print_section("5ï¸âƒ£  éªŒè¯CUDAç¯å¢ƒ")
    
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
            mem_total = torch.cuda.get_device_properties(i).total_memory / (1024**3)
            print(f"         æ˜¾å­˜: {mem_total:.2f} GB")
        return True
    else:
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆéå¸¸æ…¢ï¼‰")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸ” FG-CLIP è®­ç»ƒå‰ç½®éªŒè¯".center(70, "="))
    print("Version: 2025-10-12")
    print("="*70)
    
    results = {}
    
    # æ‰§è¡Œæ‰€æœ‰éªŒè¯
    results['json_format'] = validate_json_format()
    results['video_paths'] = validate_video_paths()
    results['model_loading'] = validate_model_loading()
    results['cuda'] = validate_cuda()
    results['data_loading'] = validate_data_loading()
    
    # æ€»ç»“
    print_section("ğŸ“Š éªŒè¯æ€»ç»“")
    
    total = len(results)
    passed = sum(results.values())
    
    for name, status in results.items():
        icon = "âœ…" if status else "âŒ"
        print(f"{icon} {name.replace('_', ' ').title()}")
    
    print(f"\n{'='*70}")
    print(f"æ€»è®¡: {passed}/{total} é¡¹é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰éªŒè¯é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒï¼")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("   cd /data/zyy/wsvad/2026CVPR/FG-CLIP")
        print("   bash scripts/train_ucf_debug.sh")
        return 0
    else:
        print("\nâš ï¸  å­˜åœ¨éªŒè¯å¤±è´¥é¡¹ï¼Œè¯·å…ˆä¿®å¤é—®é¢˜å†å¼€å§‹è®­ç»ƒ")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
