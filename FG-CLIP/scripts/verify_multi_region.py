#!/usr/bin/env python3
"""
å¿«é€ŸéªŒè¯å¤šRegionæ•°æ®åŠ è½½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import json
import torch
from transformers import CLIPImageProcessor, CLIPTokenizer

class SimpleArgs:
    """ç®€å•çš„å‚æ•°ç±»ç”¨äºæµ‹è¯•"""
    def __init__(self):
        self.data_path = "/data/zyy/wsvad/2026CVPR/FG-CLIP/data/ucf_fgclip_train_with_timestamps.json"
        self.image_folder = "/data/zyy/dataset"
        self.is_video = True
        self.num_frames = 64  # æµ‹è¯•ç”¨è¾ƒå°çš„å¸§æ•°
        self.max_seq_length = 77
        self.base_seq_length = 32
        self.base_image_size = 224
        self.add_box_loss = True
        self.use_hard_neg = False

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("=" * 60)
    print("ğŸ§ª å¤šRegionæ•°æ®åŠ è½½éªŒè¯")
    print("=" * 60)
    
    # 1. æ£€æŸ¥æ•°æ®æ–‡ä»¶
    args = SimpleArgs()
    print(f"\n1ï¸âƒ£ æ£€æŸ¥æ•°æ®æ–‡ä»¶: {args.data_path}")
    
    if not os.path.exists(args.data_path):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        print(f"   è¯·å…ˆè¿è¡Œ: python3 data/generate_ucf_fgclip_data.py")
        return False
    
    with open(args.data_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"âœ… æ•°æ®æ–‡ä»¶å­˜åœ¨")
    print(f"   - æ€»æ ·æœ¬æ•°: {len(data)}")
    print(f"   - å¼‚å¸¸è§†é¢‘: {sum(1 for x in data if not x.get('timestamps'))}")
    print(f"   - æ­£å¸¸ç‰‡æ®µ: {sum(1 for x in data if x.get('timestamps'))}")
    
    # 2. æ£€æŸ¥regionæ•°é‡
    print(f"\n2ï¸âƒ£ ç»Ÿè®¡regionæ•°é‡")
    total_regions = 0
    abnormal_regions = 0
    normal_regions = 0
    
    for item in data:
        num_regions = len(item.get('region_captions', []))
        total_regions += num_regions
        
        if item.get('timestamps'):
            normal_regions += num_regions
        else:
            abnormal_regions += num_regions
    
    print(f"âœ… Regionç»Ÿè®¡:")
    print(f"   - æ€»regions: {total_regions}")
    print(f"   - å¼‚å¸¸è§†é¢‘regions: {abnormal_regions}")
    print(f"   - æ­£å¸¸è§†é¢‘regions: {normal_regions}")
    
    # 3. æµ‹è¯•DatasetåŠ è½½
    print(f"\n3ï¸âƒ£ æµ‹è¯•Datasetåˆå§‹åŒ–")
    try:
        from fgclip.train.train_fgclip import LazySupervisedBboxDataset
        
        # åˆ›å»ºç®€å•çš„é¢„å¤„ç†å™¨
        preprocess = CLIPImageProcessor.from_pretrained("openai/clip-vit-base-patch32")
        tokenizer = CLIPTokenizer.from_pretrained("openai/clip-vit-base-patch32")
        
        dataset = LazySupervisedBboxDataset(
            data_path=args.data_path,
            data_args=args,
            img_preprocess=preprocess,
            tokenizer=tokenizer
        )
        
        print(f"âœ… Datasetåˆå§‹åŒ–æˆåŠŸ")
        print(f"   - Dataseté•¿åº¦: {len(dataset)}")
        print(f"   - é¢„æœŸé•¿åº¦: {total_regions}")
        
        if len(dataset) != total_regions:
            print(f"âš ï¸  è­¦å‘Š: Dataseté•¿åº¦ä¸regionæ€»æ•°ä¸åŒ¹é…ï¼")
        
    except Exception as e:
        print(f"âŒ Datasetåˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 4. æµ‹è¯•å•ä¸ªæ ·æœ¬åŠ è½½
    print(f"\n4ï¸âƒ£ æµ‹è¯•æ ·æœ¬åŠ è½½ï¼ˆå‰3ä¸ªï¼‰")
    try:
        for i in range(min(3, len(dataset))):
            print(f"\n   æ ·æœ¬ {i}:")
            sample = dataset[i]
            
            print(f"   - video shape: {sample['video'].shape}")
            print(f"   - text shape: {sample['text'].shape}")
            print(f"   - short_text shape: {sample['short_text'].shape}")
            
            if sample['add_box_loss']:
                print(f"   - box_texts shape: {sample['box_texts'].shape}")
                print(f"   - box_infos shape: {sample['box_infos'].shape}")
                print(f"   - bbox_mask shape: {sample['bbox_mask'].shape}")
                print(f"   - box_nums: {sample['box_nums'].item()}")
            
            # æ£€æŸ¥bboxç»´åº¦
            if sample['add_box_loss']:
                box_infos = sample['box_infos']
                if box_infos.dim() == 3 and box_infos.shape[1] == 1:
                    print(f"   âœ… Bbox shapeæ­£ç¡® (T, 1, 4)")
                else:
                    print(f"   âš ï¸  Bbox shapeå¯èƒ½ä¸æ­£ç¡®: {box_infos.shape}")
        
        print(f"\nâœ… æ ·æœ¬åŠ è½½æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ æ ·æœ¬åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 5. æµ‹è¯•Collator
    print(f"\n5ï¸âƒ£ æµ‹è¯•Collator")
    try:
        from fgclip.train.train_fgclip import DataCollatorForSupervisedDataset
        
        collator = DataCollatorForSupervisedDataset()
        
        # å–2ä¸ªæ ·æœ¬ç»„æˆbatch
        samples = [dataset[i] for i in range(min(2, len(dataset)))]
        batch = collator(samples)
        
        print(f"âœ… CollatoræˆåŠŸ")
        print(f"   - image shape: {batch['image'].shape}")
        print(f"   - text_long shape: {batch['text_long'].shape}")
        print(f"   - text_short shape: {batch['text_short'].shape}")
        
        if batch['add_box_loss']:
            print(f"   - box_texts shape: {batch['box_texts'].shape}")
            print(f"   - box_infos shape: {batch['box_infos'].shape}")
            print(f"   - bbox_mask shape: {batch['bbox_mask'].shape}")
            
            # æ£€æŸ¥batchçš„bboxç»´åº¦
            box_infos = batch['box_infos']
            if box_infos.dim() == 4 and box_infos.shape[2] == 1:
                print(f"   âœ… Batch bbox shapeæ­£ç¡® (B, T, 1, 4)")
            else:
                print(f"   âš ï¸  Batch bbox shapeå¯èƒ½ä¸æ­£ç¡®: {box_infos.shape}")
        
    except Exception as e:
        print(f"âŒ Collatorå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 6. éªŒè¯timestampsä½¿ç”¨
    print(f"\n6ï¸âƒ£ éªŒè¯timestampsä½¿ç”¨")
    try:
        # æ‰¾ä¸€ä¸ªæ­£å¸¸è§†é¢‘æ ·æœ¬
        normal_idx = None
        for i, item in enumerate(data):
            if item.get('timestamps'):
                # é€šè¿‡region_index_mapæ‰¾åˆ°å¯¹åº”çš„æ ·æœ¬ç´¢å¼•
                region_count = 0
                for j, video_item in enumerate(data):
                    num_regions = len(video_item.get('region_captions', []))
                    if j == i:
                        normal_idx = region_count
                        break
                    region_count += num_regions
                break
        
        if normal_idx is not None:
            print(f"   - æ‰¾åˆ°æ­£å¸¸è§†é¢‘æ ·æœ¬ç´¢å¼•: {normal_idx}")
            sample = dataset[normal_idx]
            print(f"   - è§†é¢‘å¸§æ•°: {sample['video'].shape[0]}")
            print(f"   âœ… TimestampsåŠŸèƒ½æ­£å¸¸ï¼ˆå·²åŠ è½½æ­£å¸¸è§†é¢‘ç‰‡æ®µï¼‰")
        else:
            print(f"   âš ï¸  æœªæ‰¾åˆ°æ­£å¸¸è§†é¢‘æ ·æœ¬")
        
    except Exception as e:
        print(f"âŒ TimestampséªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰éªŒè¯é€šè¿‡ï¼æ•°æ®åŠ è½½å·¥ä½œæ­£å¸¸")
    print("=" * 60)
    print("\nğŸš€ å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼")
    print("   è¿è¡Œ: bash scripts/train_ucf_full.sh")
    
    return True

if __name__ == "__main__":
    success = test_data_loading()
    sys.exit(0 if success else 1)
